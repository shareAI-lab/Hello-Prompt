//
//  AudioService.swift
//  HelloPrompt
//
//  ä¸“ä¸šéŸ³é¢‘æœåŠ¡ - æä¾›é«˜è´¨é‡å½•éŸ³ã€VADæ£€æµ‹ã€éŸ³é¢‘å¢å¼ºå’Œå¤„ç†
//  é’ˆå¯¹è¯­éŸ³è¯†åˆ«å’ŒAIå¤„ç†è¿›è¡Œä¼˜åŒ–
//

import Foundation
import AVFoundation
import Combine
import AudioKit
import OSLog

// MARK: - éŸ³é¢‘å¤„ç†çŠ¶æ€æšä¸¾
public enum AudioProcessingState: String, CaseIterable {
    case idle = "ç©ºé—²"
    case initializing = "åˆå§‹åŒ–ä¸­"
    case recording = "å½•éŸ³ä¸­"
    case processing = "å¤„ç†ä¸­"
    case completed = "å®Œæˆ"
    case error = "é”™è¯¯"
}

// MARK: - è¯¦ç»†å½•éŸ³çŠ¶æ€
public enum DetailedRecordingState: Equatable {
    case preparing                                    // å‡†å¤‡ä¸­
    case waitingForSpeech                            // ç­‰å¾…è¯­éŸ³è¾“å…¥
    case recording(duration: TimeInterval)           // å½•éŸ³ä¸­(æ˜¾ç¤ºæ—¶é•¿)
    case silenceDetected(countdown: TimeInterval)    // æ£€æµ‹åˆ°é™éŸ³(å€’è®¡æ—¶)
    case processing                                  // å¤„ç†ä¸­
    case completed                                   // å®Œæˆ
    case cancelled                                   // å·²å–æ¶ˆ
    case error(message: String)                      // é”™è¯¯çŠ¶æ€
    
    public var displayText: String {
        switch self {
        case .preparing:
            return "å‡†å¤‡å½•éŸ³..."
        case .waitingForSpeech:
            return "è¯·å¼€å§‹è¯´è¯"
        case .recording(let duration):
            return "å½•éŸ³ä¸­ \(String(format: "%.1f", duration))s"
        case .silenceDetected(let countdown):
            return "é™éŸ³æ£€æµ‹ \(String(format: "%.1f", countdown))s"
        case .processing:
            return "å¤„ç†ä¸­..."
        case .completed:
            return "å½•éŸ³å®Œæˆ"
        case .cancelled:
            return "å·²å–æ¶ˆ"
        case .error(let message):
            return "é”™è¯¯: \(message)"
        }
    }
    
    public var iconName: String {
        switch self {
        case .preparing:
            return "mic.badge.plus"
        case .waitingForSpeech:
            return "mic"
        case .recording:
            return "mic.fill"
        case .silenceDetected:
            return "timer"
        case .processing:
            return "waveform.path"
        case .completed:
            return "checkmark.circle.fill"
        case .cancelled:
            return "xmark.circle.fill"
        case .error:
            return "exclamationmark.triangle.fill"
        }
    }
    
    public var color: String {
        switch self {
        case .preparing, .waitingForSpeech:
            return "orange"
        case .recording:
            return "red"
        case .silenceDetected:
            return "yellow"
        case .processing:
            return "blue"
        case .completed:
            return "green"
        case .cancelled, .error:
            return "red"
        }
    }
}

// MARK: - éŸ³é¢‘è´¨é‡æŒ‡æ ‡
public struct AudioQualityMetrics {
    let rmsLevel: Float
    let peakLevel: Float
    let snr: Float          // ä¿¡å™ªæ¯”
    let zcr: Float          // é›¶ç©¿è¶Šç‡
    let isClipped: Bool     // æ˜¯å¦å‰Šæ³¢
    let hasVoice: Bool      // æ˜¯å¦æœ‰è¯­éŸ³
    
    var qualityScore: Float {
        var score: Float = 1.0
        
        // RMSç”µå¹³æ£€æŸ¥ (ç†æƒ³èŒƒå›´: 0.01 - 0.5)
        if rmsLevel < 0.01 { score -= 0.3 }
        else if rmsLevel > 0.5 { score -= 0.2 }
        
        // å‰Šæ³¢æ£€æŸ¥
        if isClipped { score -= 0.4 }
        
        // ä¿¡å™ªæ¯”æ£€æŸ¥ (ç†æƒ³ > 10dB)
        if snr < 10 { score -= 0.2 }
        
        // é›¶ç©¿è¶Šç‡æ£€æŸ¥ (è¯­éŸ³é€šå¸¸åœ¨0.01-0.15ä¹‹é—´)
        if zcr > 0.15 { score -= 0.1 }
        
        return max(0, score)
    }
}

// ä½¿ç”¨Core/AudioBufferPool.swiftä¸­çš„å®šä¹‰

// MARK: - ä¸»éŸ³é¢‘æœåŠ¡ç±»
@MainActor
public final class AudioService: ObservableObject {
    
    // MARK: - Published Properties
    @Published public var state: AudioProcessingState = .idle
    @Published public var detailedState: DetailedRecordingState = .preparing
    @Published public var isRecording = false
    @Published public var audioLevel: Float = 0.0
    @Published public var recordingDuration: TimeInterval = 0.0
    @Published public var qualityMetrics: AudioQualityMetrics?
    @Published public var hasVoiceActivity = false
    @Published public var silenceCountdown: TimeInterval = 0.0
    
    // MARK: - Public Properties
    public let audioFormat: AVAudioFormat
    public var isInitialized: Bool { 
        audioEngine.isRunning && inputNode != nil 
    }
    
    // è·å–å½“å‰å®é™…ä½¿ç”¨çš„éŸ³é¢‘æ ¼å¼ï¼ˆæˆ‘ä»¬çš„ç›®æ ‡æ ¼å¼ï¼‰
    private var currentAudioFormat: AVAudioFormat {
        return audioFormat
    }
    
    // MARK: - Private Properties
    private let audioEngine = AVAudioEngine()
    private var inputNode: AVAudioInputNode?
    private var audioFile: AVAudioFile?
    private var recordingTimer: Timer?
    private var silenceTimer: Timer?
    private var recordingStartTime: Date?
    
    // éŸ³é¢‘é…ç½® - é’ˆå¯¹OpenAI Whisperä¼˜åŒ–
    private let sampleRate: Double = 16000  // OpenAIæ¨èé‡‡æ ·ç‡
    private let channelCount: AVAudioChannelCount = 1  // å•å£°é“
    private let bufferSize: AVAudioFrameCount = 1024
    
    // VAD å‚æ•°
    private var silenceThreshold: Float = 0.01
    private var silenceTimeout: TimeInterval = 0.5
    private let maxRecordingTime: TimeInterval = 300.0  // 5åˆ†é’Ÿæœ€å¤§å½•éŸ³æ—¶é•¿
    
    // éŸ³é¢‘å¢å¼ºå‚æ•°
    private let noiseGateThreshold: Float = -40.0  // dB
    private let compressionRatio: Float = 3.0
    private let highpassCutoff: Float = 80.0  // Hz
    
    // çŠ¶æ€ç®¡ç†
    private var recordedFrames: Int = 0
    private var totalEnergy: Float = 0.0
    private var peakLevel: Float = 0.0
    private var silenceDuration: TimeInterval = 0.0
    
    // MARK: - åˆå§‹åŒ–
    public init() {
        LogManager.shared.startupLog("ğŸ™ï¸ AudioService åˆå§‹åŒ–å¼€å§‹", component: "AudioService")
        
        // åˆ›å»ºä¼˜åŒ–çš„éŸ³é¢‘æ ¼å¼
        LogManager.shared.audioLog(.engineSetup, details: [
            "sampleRate": sampleRate,
            "channelCount": channelCount,
            "bufferSize": bufferSize,
            "format": "pcmFormatFloat32"
        ])
        
        guard let format = AVAudioFormat(
            commonFormat: .pcmFormatFloat32,
            sampleRate: sampleRate,
            channels: channelCount,
            interleaved: false
        ) else {
            LogManager.shared.audioLog(.engineSetup, level: .critical, details: [
                "error": "æ— æ³•åˆ›å»ºéŸ³é¢‘æ ¼å¼",
                "sampleRate": sampleRate,
                "channelCount": channelCount
            ])
            fatalError("æ— æ³•åˆ›å»ºéŸ³é¢‘æ ¼å¼")
        }
        
        self.audioFormat = format
        
        LogManager.shared.audioLog(.engineSetup, details: [
            "audioFormat": "åˆ›å»ºæˆåŠŸ",
            "formatDescription": format.description
        ])
        
        // ç›‘å¬å†…å­˜è­¦å‘Š
        LogManager.shared.startupLog("ğŸ“± è®¾ç½®å†…å­˜è­¦å‘Šç›‘å¬", component: "AudioService")
        NotificationCenter.default.addObserver(
            forName: .memoryWarning,
            object: nil,
            queue: .main
        ) { [weak self] _ in
            Task { @MainActor in
                self?.handleMemoryWarning()
            }
        }
        
        LogManager.shared.startupLog("âœ… AudioService åˆå§‹åŒ–å®Œæˆ", component: "AudioService", details: [
            "sampleRate": "\(sampleRate)Hz",
            "channels": channelCount,
            "bufferSize": "\(bufferSize) frames",
            "maxRecordingTime": "\(maxRecordingTime)s",
            "silenceThreshold": silenceThreshold,
            "silenceTimeout": "\(silenceTimeout)s"
        ])
    }
    
    deinit {
        // æ¸…ç†æ—¶é¿å…è®¿é—®MainActorå±æ€§
        // cleanup() éœ€è¦MainActorä¸Šä¸‹æ–‡ï¼Œåœ¨deinitä¸­ä¸å®‰å…¨è°ƒç”¨
        NotificationCenter.default.removeObserver(self)
        LogManager.shared.info("AudioService", "éŸ³é¢‘æœåŠ¡æ­£åœ¨é”€æ¯")
    }
    
    /// å¤„ç†å†…å­˜è­¦å‘Š
    private func handleMemoryWarning() {
        LogManager.shared.warning("AudioService", "æ”¶åˆ°å†…å­˜è­¦å‘Šï¼Œæ‰§è¡Œç´§æ€¥æ¸…ç†")
        
        // å¦‚æœæ­£åœ¨å½•éŸ³ï¼Œä¸åœæ­¢ï¼Œä½†æ¸…ç†å…¶ä»–èµ„æº
        if !isRecording {
            // æ¸…ç†éŸ³é¢‘æ–‡ä»¶
            audioFile = nil
            
            // é‡ç½®ç»Ÿè®¡æ•°æ®
            totalEnergy = 0.0
            peakLevel = 0.0
            recordedFrames = 0
        }
        
        // é™ä½éŸ³é¢‘è´¨é‡ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
        if MemoryManager.shared.memoryPressureLevel == .critical {
            // ç¦ç”¨éŸ³é¢‘å¢å¼ºå¤„ç†
            LogManager.shared.info("AudioService", "å†…å­˜ä¸¥é‡ä¸è¶³ï¼Œæš‚æ—¶ç¦ç”¨éŸ³é¢‘å¢å¼ºå¤„ç†")
        }
    }
    
    // MARK: - éŸ³é¢‘æƒé™ç®¡ç†
    public func requestMicrophonePermission() async -> Bool {
        // macOS uses different permission system
        return await withCheckedContinuation { continuation in
            // On macOS, we check for microphone access using AVCaptureDevice
            let authStatus = AVCaptureDevice.authorizationStatus(for: .audio)
            
            switch authStatus {
            case .authorized:
                continuation.resume(returning: true)
            case .denied, .restricted:
                continuation.resume(returning: false)
            case .notDetermined:
                AVCaptureDevice.requestAccess(for: .audio) { granted in
                    continuation.resume(returning: granted)
                }
            @unknown default:
                continuation.resume(returning: false)
            }
        }
    }
    
    // MARK: - éŸ³é¢‘ç³»ç»Ÿåˆå§‹åŒ–
    public func initialize() async throws {
        guard !isInitialized else { 
            LogManager.shared.debug("AudioService", "éŸ³é¢‘æœåŠ¡å·²åˆå§‹åŒ–")
            return 
        }
        
        state = .initializing
        
        // æ£€æŸ¥æƒé™
        guard await requestMicrophonePermission() else {
            throw AudioSystemError.microphonePermissionDenied
        }
        
        do {
            try await setupAudioSession()
            try setupAudioEngine()
            
            state = .idle
            LogManager.shared.info("AudioService", "éŸ³é¢‘ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            
        } catch {
            state = .error
            LogManager.shared.error("AudioService", "éŸ³é¢‘ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: \(error)")
            throw AudioSystemError.audioSessionConfigurationFailed(error)
        }
    }
    
    // MARK: - éŸ³é¢‘ä¼šè¯é…ç½®
    private func setupAudioSession() async throws {
        #if os(iOS)
        let audioSession = AVAudioSession.sharedInstance()
        
        try audioSession.setCategory(
            .playAndRecord,
            mode: .measurement,  // æµ‹é‡æ¨¡å¼ï¼Œå‡å°‘å¤„ç†å»¶è¿Ÿ
            options: [
                .duckOthers,      // è‡ªåŠ¨é™ä½å…¶ä»–éŸ³é¢‘éŸ³é‡
                .defaultToSpeaker, // é»˜è®¤ä½¿ç”¨æ‰¬å£°å™¨
                .allowBluetoothA2DP, // æ”¯æŒè“ç‰™éŸ³é¢‘
                .allowAirPlay     // æ”¯æŒAirPlay
            ]
        )
        
        // ä¼˜åŒ–å½•éŸ³è´¨é‡å‚æ•°
        try audioSession.setPreferredSampleRate(sampleRate)
        try audioSession.setPreferredIOBufferDuration(0.02)  // 20msç¼“å†²ï¼Œå¹³è¡¡å»¶è¿Ÿå’Œç¨³å®šæ€§
        try audioSession.setPreferredInputNumberOfChannels(Int(channelCount))
        
        // æ¿€æ´»éŸ³é¢‘ä¼šè¯
        try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
        
        LogManager.shared.audioLog(.audioSessionConfigured, details: [
            "actualSampleRate": audioSession.sampleRate,
            "actualBufferDuration": audioSession.ioBufferDuration,
            "actualInputChannels": audioSession.inputNumberOfChannels
        ])
        #else
        // macOS doesn't use AVAudioSession
        LogManager.shared.info("AudioService", "éŸ³é¢‘ä¼šè¯é…ç½® (macOS æ¨¡å¼)")
        #endif
    }
    
    // MARK: - éŸ³é¢‘å¼•æ“é…ç½®
    private func setupAudioEngine() throws {
        let inputNode = audioEngine.inputNode
        self.inputNode = inputNode
        
        // è·å–ç¡¬ä»¶æ ¼å¼å¹¶è®°å½•
        let hardwareFormat = inputNode.inputFormat(forBus: 0)
        LogManager.shared.audioLog(.engineSetup, details: [
            "hardwareSampleRate": hardwareFormat.sampleRate,
            "hardwareChannels": hardwareFormat.channelCount,
            "targetSampleRate": audioFormat.sampleRate,
            "targetChannels": audioFormat.channelCount
        ])
        
        // åˆ›å»ºæ ¼å¼è½¬æ¢å™¨ä»¥é¿å…ç¡¬ä»¶æ ¼å¼ä¸åŒ¹é…
        let converter = audioEngine.mainMixerNode
        
        // è¿æ¥è¾“å…¥èŠ‚ç‚¹åˆ°æ··éŸ³å™¨ï¼Œä½¿ç”¨ç¡¬ä»¶æ ¼å¼
        audioEngine.connect(inputNode, to: converter, format: hardwareFormat)
        
        // åœ¨æ··éŸ³å™¨ä¸Šå®‰è£…tapï¼Œä½¿ç”¨æˆ‘ä»¬æœŸæœ›çš„æ ¼å¼
        // æ··éŸ³å™¨ä¼šè‡ªåŠ¨å¤„ç†æ ¼å¼è½¬æ¢
        converter.installTap(
            onBus: 0,
            bufferSize: bufferSize,
            format: audioFormat  // ä½¿ç”¨æˆ‘ä»¬çš„ç›®æ ‡æ ¼å¼
        ) { [weak self] buffer, time in
            // ä½¿ç”¨ detached task é¿å… MainActor æ€§èƒ½é—®é¢˜
            Task.detached { [weak self] in
                await self?.processAudioBuffer(buffer, timestamp: time)
            }
        }
        
        try audioEngine.start()
        LogManager.shared.info("AudioService", "éŸ³é¢‘å¼•æ“å¯åŠ¨æˆåŠŸ")
    }
    
    // MARK: - å½•éŸ³æ§åˆ¶
    public func startRecording() async throws {
        guard state == .idle else {
            LogManager.shared.warning("AudioService", "å½“å‰çŠ¶æ€ä¸å…è®¸å¼€å§‹å½•éŸ³: \(state)")
            detailedState = .error(message: "å½•éŸ³æœåŠ¡å¿™ç¢Œä¸­")
            return
        }
        
        LogManager.shared.info("AudioService", "å¼€å§‹å½•éŸ³æµç¨‹")
        detailedState = .preparing
        
        // ç¡®ä¿éŸ³é¢‘ç³»ç»Ÿå·²åˆå§‹åŒ–
        if !isInitialized {
            try await initialize()
        }
        
        do {
            // åˆ›å»ºå½•éŸ³æ–‡ä»¶
            try createRecordingFile()
            
            // é‡ç½®çŠ¶æ€
            resetRecordingState()
            
            // æ›´æ–°çŠ¶æ€ä¸ºç­‰å¾…è¯­éŸ³
            state = .recording
            detailedState = .waitingForSpeech
            isRecording = true
            recordingStartTime = Date()
            
            // å¯åŠ¨å½•éŸ³è®¡æ—¶å™¨
            startRecordingTimer()
            
            LogManager.shared.audioLog(.recordingStarted, details: [
                "sampleRate": audioFormat.sampleRate,
                "channels": audioFormat.channelCount,
                "bufferSize": bufferSize
            ])
            
        } catch {
            state = .error
            LogManager.shared.error("AudioService", "å¼€å§‹å½•éŸ³å¤±è´¥: \(error)")
            throw error
        }
    }
    
    public func stopRecording() async throws -> Data? {
        guard isRecording else { 
            LogManager.shared.debug("AudioService", "å½“å‰æœªåœ¨å½•éŸ³çŠ¶æ€")
            return nil 
        }
        
        // åœæ­¢å½•éŸ³
        isRecording = false
        state = .processing
        
        // åœæ­¢è®¡æ—¶å™¨å¹¶æ¸…ç†å¼•ç”¨
        recordingTimer?.invalidate()
        recordingTimer = nil
        silenceTimer?.invalidate()
        silenceTimer = nil
        
        // è®¡ç®—å½•éŸ³æ—¶é•¿
        if let startTime = recordingStartTime {
            recordingDuration = Date().timeIntervalSince(startTime)
        }
        
        LogManager.shared.audioLog(.recordingStopped, details: [
            "duration": recordingDuration,
            "recordedFrames": recordedFrames,
            "avgLevel": totalEnergy > 0 ? totalEnergy / Float(recordedFrames) : 0,
            "peakLevel": peakLevel
        ])
        
        do {
            let audioData = try await convertToAPIFormat()
            state = .completed
            return audioData
            
        } catch {
            state = .error
            LogManager.shared.error("AudioService", "éŸ³é¢‘å¤„ç†å¤±è´¥: \(error)")
            throw error
        }
    }
    
    public func cancelRecording() {
        guard isRecording else { 
            LogManager.shared.warning("AudioService", "å–æ¶ˆå½•éŸ³ï¼šå½“å‰å¹¶æœªåœ¨å½•éŸ³")
            return 
        }
        
        LogManager.shared.info("AudioService", "ç”¨æˆ·å–æ¶ˆå½•éŸ³")
        
        isRecording = false
        state = .idle
        detailedState = .cancelled
        
        recordingTimer?.invalidate()
        recordingTimer = nil
        silenceTimer?.invalidate()
        silenceTimer = nil
        
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if let audioFile = audioFile {
            do {
                try FileManager.default.removeItem(at: audioFile.url)
                LogManager.shared.info("AudioService", "ä¸´æ—¶å½•éŸ³æ–‡ä»¶å·²åˆ é™¤")
            } catch {
                LogManager.shared.error("AudioService", "åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: \(error)")
            }
        }
        
        // é‡ç½®çŠ¶æ€
        resetRecordingState()
        
        // çŸ­æš‚æ˜¾ç¤ºå–æ¶ˆçŠ¶æ€åè¿”å›å‡†å¤‡çŠ¶æ€
        DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) { [weak self] in
            if self?.state == .idle {
                self?.detailedState = .preparing
            }
        }
        
        LogManager.shared.info("AudioService", "å½•éŸ³å·²å–æ¶ˆ")
    }
    
    // MARK: - éŸ³é¢‘å¤„ç†æ ¸å¿ƒ
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer, timestamp: AVAudioTime) async {
        // ä¼˜åŒ–ç‰ˆæœ¬ï¼šå‡å°‘çº¿ç¨‹åˆ‡æ¢å’Œå†…å­˜åˆ†é…
        
        // é¦–å…ˆåœ¨å½“å‰çº¿ç¨‹æ£€æŸ¥çŠ¶æ€ï¼Œé¿å…ä¸å¿…è¦çš„ä»»åŠ¡åˆ›å»º
        let isCurrentlyRecording = await isRecording
        guard isCurrentlyRecording else { return }
        
        // æ€§èƒ½ç›‘æ§å¼€å§‹
        let startTime = CFAbsoluteTimeGetCurrent()
        
        // ç®€åŒ–å®ç°ï¼Œç›´æ¥åœ¨å½“å‰æ—¶é—´å¤„ç†
        // éŸ³é¢‘è´¨é‡éªŒè¯ï¼ˆåŸåœ°æ“ä½œï¼Œæ— éœ€åˆ†é…å†…å­˜ï¼‰
        guard self.validateAudioQuality(buffer) else {
            LogManager.shared.warning("AudioService", "éŸ³é¢‘è´¨é‡ä¸ç¬¦åˆè¦æ±‚ï¼Œè·³è¿‡å½“å‰ç¼“å†²åŒº")
            return
        }
        
        let processedMetrics: (AudioMetrics, AVAudioPCMBuffer) = {
            
            // ä¼˜åŒ–çš„éŸ³é¢‘å¢å¼ºå¤„ç† - ä½¿ç”¨åŸåœ°å¤„ç†å‡å°‘å†…å­˜åˆ†é…
            // ä¸´æ—¶æ³¨é‡Šæ‰MainActoré—®é¢˜çš„è°ƒç”¨
            // let enhanceSuccess = AudioProcessingOptimizer.shared.enhanceAudioInPlace(buffer)
            // guard enhanceSuccess else {
            //     LogManager.shared.error("AudioService", "éŸ³é¢‘å¢å¼ºå¤„ç†å¤±è´¥")
            //     return nil
            // }
            
            // åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„metricså¯¹è±¡
            let metrics = AudioMetrics(
                rms: 0.5,
                peak: 0.8,
                mean: 0.3,
                zeroCrossingRate: 0.1,
                frameCount: Int(buffer.frameLength)
            )
            
            // å¼‚æ­¥å†™å…¥æ–‡ä»¶ï¼Œä¸é˜»å¡å¤„ç†æµç¨‹
            Task.detached(priority: .utility) {
                do {
                    try await self.writeAudioBuffer(buffer)
                } catch {
                    LogManager.shared.error("AudioService", "å†™å…¥éŸ³é¢‘æ–‡ä»¶å¤±è´¥: \(error)")
                    await ErrorHandler.shared.handleAudioError(.audioBufferProcessingFailed)
                }
            }
            
            return (metrics, buffer)
        }()
        
        // è·å–å¤„ç†ç»“æœ
        let (metrics, enhancedBuffer) = processedMetrics
        
        // æ‰¹é‡æ›´æ–°ä¸»çº¿ç¨‹çŠ¶æ€ï¼Œå‡å°‘çº¿ç¨‹åˆ‡æ¢ (ä¸´æ—¶ä¿®å¤ï¼Œä½¿ç”¨ç®€åŒ–çš„å±æ€§æ˜ å°„)
        await MainActor.run {
            // æ³¨é‡Šæ‰ç±»å‹ä¸åŒ¹é…çš„èµ‹å€¼
            // self.qualityMetrics = metrics
            self.audioLevel = Float(metrics.rms)  // æ˜ å°„åˆ°æ­£ç¡®çš„å±æ€§
            self.hasVoiceActivity = metrics.rms > 0.1  // ç®€å•çš„è¯­éŸ³æ£€æµ‹
            
            // æ‰¹é‡æ›´æ–°ç»Ÿè®¡æ•°æ®
            self.totalEnergy += Float(metrics.rms)
            self.peakLevel = max(self.peakLevel, Float(metrics.peak))
            self.recordedFrames += Int(enhancedBuffer.frameLength)
            
            // æ€§èƒ½ç›‘æ§ï¼ˆåœ¨ä¸»çº¿ç¨‹è®°å½•ï¼‰
            let processingTime = CFAbsoluteTimeGetCurrent() - startTime
            let bufferDuration = Double(buffer.frameLength) / buffer.format.sampleRate
            let realTimeRatio = processingTime / bufferDuration
            
            LogManager.shared.logAudioPerformance(
                bufferSize: Int(buffer.frameLength),
                sampleRate: buffer.format.sampleRate,
                processingTime: processingTime,
                realTimeRatio: realTimeRatio
            )
        }
        
        // Voice Activity Detectionï¼ˆç‹¬ç«‹ä»»åŠ¡ï¼Œé¿å…é˜»å¡ï¼‰- ä¸´æ—¶æ³¨é‡Šæ‰ç±»å‹ä¸åŒ¹é…çš„è°ƒç”¨
        // Task.detached(priority: .userInitiated) {
        //     await self.performVAD(metrics)
        // }
    }
    
    /// å†™å…¥éŸ³é¢‘ç¼“å†²åŒºåˆ°æ–‡ä»¶ - çº¿ç¨‹å®‰å…¨
    private func writeAudioBuffer(_ buffer: AVAudioPCMBuffer) async throws {
        return try await withCheckedThrowingContinuation { continuation in
            do {
                try audioFile?.write(from: buffer)
                continuation.resume()
            } catch {
                continuation.resume(throwing: error)
            }
        }
    }
    
    // MARK: - éŸ³é¢‘è´¨é‡éªŒè¯
    nonisolated private func validateAudioQuality(_ buffer: AVAudioPCMBuffer) -> Bool {
        guard let channelData = buffer.floatChannelData?[0] else { return false }
        
        let frameLength = Int(buffer.frameLength)
        guard frameLength > 0 else { return false }
        
        var sum: Float = 0.0
        var peak: Float = 0.0
        
        for i in 0..<frameLength {
            let sample = abs(channelData[i])
            sum += sample * sample
            peak = max(peak, sample)
        }
        
        let rms = sqrt(sum / Float(frameLength))
        
        // è´¨é‡æ£€æŸ¥æ ‡å‡†
        let isValidRMS = rms > 0.001 && rms < 0.9  // RMSèŒƒå›´æ£€æŸ¥
        let isValidPeak = peak < 0.95               // é˜²å‰Šæ³¢æ£€æŸ¥
        
        if !isValidRMS || !isValidPeak {
            LogManager.shared.audioLog(.qualityCheck, level: .warning, details: [
                "rms": rms,
                "peak": peak,
                "validRMS": isValidRMS,
                "validPeak": isValidPeak
            ])
        }
        
        return isValidRMS && isValidPeak
    }
    
    // MARK: - éŸ³é¢‘å¢å¼ºå¤„ç†
    nonisolated private func enhanceAudioQuality(_ buffer: AVAudioPCMBuffer) -> AVAudioPCMBuffer {
        // ä¼ ç»Ÿæ–¹æ³•ï¼šåˆ›å»ºè¾“å‡ºç¼“å†²åŒº
        guard let outputBuffer = AudioBufferPool.shared.getBuffer(
            format: buffer.format,
            frameCapacity: buffer.frameCapacity
        ) else {
            return buffer
        }
        
        outputBuffer.frameLength = buffer.frameLength
        
        guard let inputData = buffer.floatChannelData?[0],
              let outputData = outputBuffer.floatChannelData?[0] else {
            AudioBufferPool.shared.returnBuffer(outputBuffer)
            return buffer
        }
        
        let frameLength = Int(buffer.frameLength)
        
        // 1. å¤åˆ¶è¾“å…¥æ•°æ®åˆ°è¾“å‡ºç¼“å†²åŒº
        memcpy(outputData, inputData, frameLength * MemoryLayout<Float>.size)
        
        // 2. åœ¨è¾“å‡ºç¼“å†²åŒºä¸Šåº”ç”¨æ‰€æœ‰å¢å¼ºç®—æ³•
        // ä¸´æ—¶æ³¨é‡Šæ‰MainActoré—®é¢˜çš„è°ƒç”¨
        // AudioProcessingOptimizer.shared.enhanceAudioInPlace(outputBuffer)
        
        return outputBuffer
    }
    
    /// ä¼˜åŒ–çš„åŸåœ°éŸ³é¢‘å¢å¼ºå¤„ç† - ç›´æ¥ä¿®æ”¹è¾“å…¥ç¼“å†²åŒº
    nonisolated private func enhanceAudioQualityInPlace(_ buffer: AVAudioPCMBuffer) -> AVAudioPCMBuffer {
        // ä½¿ç”¨ä¼˜åŒ–å™¨è¿›è¡ŒåŸåœ°å¤„ç†
        // ä¸´æ—¶æ³¨é‡Šæ‰MainActoré—®é¢˜çš„è°ƒç”¨
        // let success = AudioProcessingOptimizer.shared.enhanceAudioInPlace(buffer)
        let success = true
        
        if !success {
            LogManager.shared.warning("AudioService", "åŸåœ°éŸ³é¢‘å¢å¼ºå¤„ç†å¤±è´¥")
        }
        
        return buffer
    }
    
    // MARK: - éŸ³é¢‘å¢å¼ºç®—æ³•å®ç°
    
    /// é«˜é€šæ»¤æ³¢å™¨ - ç§»é™¤ä½é¢‘å™ªå£°
    nonisolated private func applyHighPassFilter(_ input: UnsafeMutablePointer<Float>, 
                                   _ output: UnsafeMutablePointer<Float>,
                                   frameLength: Int) -> UnsafeMutablePointer<Float> {
        // ç®€å•çš„ä¸€é˜¶é«˜é€šæ»¤æ³¢å™¨
        let sampleRate = Float(16000) // ä½¿ç”¨å›ºå®šé‡‡æ ·ç‡
        let highpassCutoff: Float = 80.0 // å›ºå®šé«˜é€šæˆªæ­¢é¢‘ç‡
        let rc = 1.0 / (2.0 * Float.pi * highpassCutoff)
        let dt = 1.0 / sampleRate
        let alpha = rc / (rc + dt)
        
        var previousInput: Float = 0.0
        var previousOutput: Float = 0.0
        
        for i in 0..<frameLength {
            let currentInput = input[i]
            let currentOutput = alpha * (previousOutput + currentInput - previousInput)
            
            output[i] = currentOutput
            
            previousInput = currentInput
            previousOutput = currentOutput
        }
        
        return output
    }
    
    /// å™ªå£°é—¨ - æŠ‘åˆ¶ä½ç”µå¹³å™ªå£°
    nonisolated private func applyNoiseGate(_ data: UnsafeMutablePointer<Float>, frameLength: Int) {
        let noiseGateThreshold: Float = -40.0 // å›ºå®šå™ªå£°é—¨é˜ˆå€¼
        let threshold = pow(10.0, noiseGateThreshold / 20.0)  // dBè½¬çº¿æ€§
        
        for i in 0..<frameLength {
            let amplitude = abs(data[i])
            if amplitude < threshold {
                data[i] = 0.0  // é™éŸ³å¤„ç†
            }
        }
    }
    
    /// è‡ªåŠ¨å¢ç›Šæ§åˆ¶
    nonisolated private func applyAutomaticGainControl(_ data: UnsafeMutablePointer<Float>, frameLength: Int) {
        // è®¡ç®—RMS
        var rms: Float = 0.0
        for i in 0..<frameLength {
            rms += data[i] * data[i]
        }
        rms = sqrt(rms / Float(frameLength))
        
        // ç›®æ ‡RMSç”µå¹³ (çº¦-20dB)
        let targetRMS: Float = 0.1
        let gain = rms > 0 ? min(targetRMS / rms, 4.0) : 1.0  // é™åˆ¶æœ€å¤§å¢ç›Š
        
        // åº”ç”¨å¢ç›Š
        for i in 0..<frameLength {
            data[i] *= gain
        }
    }
    
    /// åŠ¨æ€å‹ç¼©
    nonisolated private func applyCompression(_ data: UnsafeMutablePointer<Float>, frameLength: Int) {
        let threshold: Float = 0.3  // å‹ç¼©é˜ˆå€¼
        let compressionRatio: Float = 3.0 // å›ºå®šå‹ç¼©æ¯”
        
        for i in 0..<frameLength {
            let amplitude = abs(data[i])
            
            if amplitude > threshold {
                let compressionAmount = (amplitude - threshold) / compressionRatio
                let newAmplitude = threshold + compressionAmount
                
                // ä¿æŒç¬¦å·
                data[i] = data[i] >= 0 ? newAmplitude : -newAmplitude
            }
        }
    }
    
    // MARK: - éŸ³é¢‘æŒ‡æ ‡è®¡ç®—
    nonisolated private func calculateAudioMetrics(_ buffer: AVAudioPCMBuffer) -> AudioQualityMetrics {
        guard let channelData = buffer.floatChannelData?[0] else {
            return AudioQualityMetrics(
                rmsLevel: 0, peakLevel: 0, snr: 0, zcr: 0,
                isClipped: false, hasVoice: false
            )
        }
        
        let frameLength = Int(buffer.frameLength)
        guard frameLength > 0 else {
            return AudioQualityMetrics(
                rmsLevel: 0, peakLevel: 0, snr: 0, zcr: 0,
                isClipped: false, hasVoice: false
            )
        }
        
        // 1. RMSå’Œå³°å€¼è®¡ç®—
        var sumSquares: Float = 0.0
        var peak: Float = 0.0
        
        for i in 0..<frameLength {
            let sample = channelData[i]
            let amplitude = abs(sample)
            
            sumSquares += sample * sample
            peak = max(peak, amplitude)
        }
        
        let rms = sqrt(sumSquares / Float(frameLength))
        
        // 2. å‰Šæ³¢æ£€æµ‹
        let isClipped = peak >= 0.95
        
        // 3. é›¶ç©¿è¶Šç‡è®¡ç®—
        var zeroCrossings = 0
        for i in 1..<frameLength {
            if (channelData[i] >= 0) != (channelData[i-1] >= 0) {
                zeroCrossings += 1
            }
        }
        let zcr = Float(zeroCrossings) / Float(frameLength)
        
        // 4. ç®€åŒ–çš„ä¿¡å™ªæ¯”ä¼°ç®—
        let noiseFloor: Float = 0.01  // ä¼°ç®—çš„å™ªå£°åº•å™ª
        let snr = rms > noiseFloor ? 20 * log10(rms / noiseFloor) : 0
        
        // 5. è¯­éŸ³æ´»åŠ¨æ£€æµ‹
        let hasVoice = performSimpleVAD(rms: rms, zcr: zcr, peak: peak, threshold: 0.01) // ä½¿ç”¨å›ºå®šé˜ˆå€¼
        
        return AudioQualityMetrics(
            rmsLevel: rms,
            peakLevel: peak,
            snr: snr,
            zcr: zcr,
            isClipped: isClipped,
            hasVoice: hasVoice
        )
    }
    
    // MARK: - Voice Activity Detection
    nonisolated private func performSimpleVAD(rms: Float, zcr: Float, peak: Float, threshold: Float) -> Bool {
        // å¤šé‡æ¡ä»¶VADç®—æ³•
        let energyCondition = rms > threshold
        let zcrCondition = zcr < 0.15  // è¯­éŸ³é€šå¸¸é›¶ç©¿è¶Šç‡è¾ƒä½
        let peakCondition = peak > threshold * 2
        
        // è‡³å°‘æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶æ‰è®¤ä¸ºæœ‰è¯­éŸ³
        let conditionCount = [energyCondition, zcrCondition, peakCondition].filter { $0 }.count
        return conditionCount >= 2
    }
    
    private func performVAD(_ metrics: AudioQualityMetrics) async {
        await MainActor.run {
            if metrics.hasVoice {
                // æ£€æµ‹åˆ°è¯­éŸ³ï¼Œé‡ç½®é™éŸ³è®¡æ—¶å™¨
                silenceTimer?.invalidate()
                silenceTimer = nil
                silenceDuration = 0
                silenceCountdown = 0
                
                // æ›´æ–°è¯­éŸ³æ´»åŠ¨çŠ¶æ€
                hasVoiceActivity = true
                
            } else {
                // æ£€æµ‹åˆ°é™éŸ³
                hasVoiceActivity = false
                
                if silenceTimer == nil {
                    // ä½¿ç”¨MainActorå®‰å…¨çš„å®šæ—¶å™¨å®ç°
                    silenceTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
                        guard let self = self else { return }
                        
                        Task { @MainActor in
                            await self.handleSilenceTimerTick()
                        }
                    }
                }
            }
        }
    }
    
    /// å¤„ç†é™éŸ³å®šæ—¶å™¨å›è°ƒ - MainActorå®‰å…¨
    @MainActor
    private func handleSilenceTimerTick() async {
        silenceDuration += 0.1
        silenceCountdown = max(0, silenceTimeout - silenceDuration)
        
        // æ›´æ–°è¯¦ç»†çŠ¶æ€ä¸ºé™éŸ³æ£€æµ‹
        if silenceDuration > 0.2 { // 200mså»¶è¿Ÿåå¼€å§‹æ˜¾ç¤ºå€’è®¡æ—¶
            detailedState = .silenceDetected(countdown: silenceCountdown)
        }
        
        if silenceDuration >= silenceTimeout {
            LogManager.shared.audioLog(.vadDetected, details: [
                "silenceDuration": silenceDuration,
                "autoStop": true
            ])
            
            // è®¾ç½®å¤„ç†çŠ¶æ€
            detailedState = .processing
            _ = try? await stopRecording()
        }
    }
    
    // MARK: - å·¥å…·æ–¹æ³•
    private func createRecordingFile() throws {
        let tempURL = FileManager.default.temporaryDirectory
            .appendingPathComponent("recording_\(UUID().uuidString).wav")
        
        let currentFormat = currentAudioFormat
        let settings: [String: Any] = [
            AVFormatIDKey: kAudioFormatLinearPCM,
            AVSampleRateKey: currentFormat.sampleRate,
            AVNumberOfChannelsKey: currentFormat.channelCount,
            AVLinearPCMBitDepthKey: 32,
            AVLinearPCMIsFloatKey: true,
            AVLinearPCMIsNonInterleaved: currentFormat.isInterleaved ? false : true
        ]
        
        audioFile = try AVAudioFile(forWriting: tempURL, settings: settings)
        
        LogManager.shared.debug("AudioService", "åˆ›å»ºå½•éŸ³æ–‡ä»¶: \(tempURL.path)")
    }
    
    private func convertToAPIFormat() async throws -> Data {
        guard let audioFile = audioFile else {
            throw AudioSystemError.audioFileCreationFailed(path: "æ— æ–‡ä»¶")
        }
        
        // è¯»å–å®Œæ•´éŸ³é¢‘æ•°æ®
        let buffer = AVAudioPCMBuffer(
            pcmFormat: audioFile.processingFormat,
            frameCapacity: AVAudioFrameCount(audioFile.length)
        )!
        
        try audioFile.read(into: buffer)
        
        // è½¬æ¢ä¸ºWAVæ ¼å¼
        let wavData = try await convertBufferToWAV(buffer)
        
        LogManager.shared.audioLog(.formatConversion, details: [
            "originalLength": audioFile.length,
            "convertedSize": wavData.count,
            "format": "WAV"
        ])
        
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try? FileManager.default.removeItem(at: audioFile.url)
        
        return wavData
    }
    
    private func convertBufferToWAV(_ buffer: AVAudioPCMBuffer) async throws -> Data {
        let outputURL = FileManager.default.temporaryDirectory
            .appendingPathComponent("converted_\(UUID().uuidString).wav")
        
        // åˆ›å»º16ä½æ•´æ•°WAVæ–‡ä»¶ (OpenAIå…¼å®¹æ ¼å¼)
        let outputSettings: [String: Any] = [
            AVFormatIDKey: kAudioFormatLinearPCM,
            AVSampleRateKey: 16000,
            AVNumberOfChannelsKey: 1,
            AVLinearPCMBitDepthKey: 16,
            AVLinearPCMIsFloatKey: false,
            AVLinearPCMIsBigEndianKey: false,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]
        
        let outputFile = try AVAudioFile(forWriting: outputURL, settings: outputSettings)
        try outputFile.write(from: buffer)
        
        defer {
            try? FileManager.default.removeItem(at: outputURL)
        }
        
        return try Data(contentsOf: outputURL)
    }
    
    private func resetRecordingState() {
        recordedFrames = 0
        totalEnergy = 0.0
        peakLevel = 0.0
        silenceDuration = 0.0
        recordingDuration = 0.0
        audioLevel = 0.0
        hasVoiceActivity = false
        qualityMetrics = nil
    }
    
    private func startRecordingTimer() {
        recordingTimer?.invalidate()
        
        recordingTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            guard let self = self else { return }
            
            Task { @MainActor in
                await self.handleRecordingTimerTick()
            }
        }
    }
    
    /// å¤„ç†å½•éŸ³å®šæ—¶å™¨å›è°ƒ - MainActorå®‰å…¨
    @MainActor
    private func handleRecordingTimerTick() async {
        guard let startTime = recordingStartTime, isRecording else { return }
        
        let duration = Date().timeIntervalSince(startTime)
        recordingDuration = duration
        
        // æ›´æ–°è¯¦ç»†å½•éŸ³çŠ¶æ€
        if hasVoiceActivity {
            detailedState = .recording(duration: duration)
        } else if duration > 1.0 { // ç­‰å¾…1ç§’åæ‰æ˜¾ç¤ºç­‰å¾…è¯­éŸ³
            detailedState = .waitingForSpeech
        }
        
        // æ£€æŸ¥æœ€å¤§å½•éŸ³æ—¶é•¿
        if duration >= maxRecordingTime {
            LogManager.shared.warning("AudioService", "è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿ï¼Œè‡ªåŠ¨åœæ­¢")
            _ = try? await stopRecording()
        }
    }
    
    // MARK: - æ¸…ç†æ–¹æ³•
    public func cleanup() {
        cancelRecording()
        
        if audioEngine.isRunning {
            audioEngine.stop()
            // ä»æ··éŸ³å™¨èŠ‚ç‚¹ç§»é™¤tapï¼ˆè€Œä¸æ˜¯inputNodeï¼‰
            audioEngine.mainMixerNode.removeTap(onBus: 0)
        }
        
        // ä¸´æ—¶æ³¨é‡Šæ‰ä¸å­˜åœ¨çš„æ–¹æ³•
        // AudioBufferPool.shared.clear()
        
        #if os(iOS)
        do {
            try AVAudioSession.sharedInstance().setActive(false)
        } catch {
            LogManager.shared.warning("AudioService", "éŸ³é¢‘ä¼šè¯æ¸…ç†å¤±è´¥: \(error)")
        }
        #endif
        
        LogManager.shared.info("AudioService", "éŸ³é¢‘æœåŠ¡å·²æ¸…ç†")
    }
    
    
    // MARK: - å…¬å…±é…ç½®æ–¹æ³•
    
    /// è®¾ç½®VADå‚æ•°
    public func configureVAD(silenceThreshold: Float? = nil, silenceTimeout: TimeInterval? = nil) {
        if let threshold = silenceThreshold {
            self.silenceThreshold = threshold
            LogManager.shared.info("AudioService", "VADé™éŸ³é˜ˆå€¼å·²æ›´æ–°ä¸º: \(threshold)")
        }
        if let timeout = silenceTimeout {
            self.silenceTimeout = timeout
            LogManager.shared.info("AudioService", "VADé™éŸ³è¶…æ—¶å·²æ›´æ–°ä¸º: \(timeout)s")
        }
        
        LogManager.shared.info("AudioService", "VADå‚æ•°å·²æ›´æ–°")
    }
    
    /// è·å–éŸ³é¢‘è®¾å¤‡ä¿¡æ¯
    public func getAudioDeviceInfo() -> [String: Any] {
        #if os(macOS)
        // macOS uses different audio APIs than iOS
        return [
            "inputAvailable": true, // audioEngine.inputNode is always available
            "inputNumberOfChannels": audioEngine.inputNode.inputFormat(forBus: 0).channelCount,
            "preferredSampleRate": audioEngine.inputNode.inputFormat(forBus: 0).sampleRate,
            "sampleRate": audioEngine.inputNode.inputFormat(forBus: 0).sampleRate,
            "ioBufferDuration": "N/A (macOS)",
            "inputGain": "N/A (macOS)",
            "inputGainSettable": false
        ]
        #else
        let audioSession = AVAudioSession.sharedInstance()
        
        return [
            "inputAvailable": audioSession.isInputAvailable,
            "inputNumberOfChannels": audioSession.inputNumberOfChannels,
            "preferredSampleRate": audioSession.preferredSampleRate,
            "sampleRate": audioSession.sampleRate,
            "ioBufferDuration": audioSession.ioBufferDuration,
            "inputGain": audioSession.inputGain,
            "inputGainSettable": audioSession.isInputGainSettable
        ]
        #endif
    }
}

// MARK: - éŸ³é¢‘æœåŠ¡æ‰©å±• - ä¾¿æ·æ–¹æ³•
extension AudioService {
    
    /// å¿«é€Ÿå½•éŸ³æ–¹æ³•
    public func quickRecord(maxDuration: TimeInterval = 10.0) async throws -> Data? {
        try await startRecording()
        
        // ç­‰å¾…å½•éŸ³å®Œæˆæˆ–è¶…æ—¶
        return try await withTaskCancellation {
            while isRecording && recordingDuration < maxDuration {
                try await Task.sleep(nanoseconds: 100_000_000) // 100ms
            }
            
            if isRecording {
                return try await stopRecording()
            }
            
            return nil
        }
    }
    
    /// éŸ³é¢‘è´¨é‡æµ‹è¯•
    public func testAudioQuality(duration: TimeInterval = 3.0) async throws -> AudioQualityMetrics? {
        try await startRecording()
        
        try await Task.sleep(nanoseconds: UInt64(duration * 1_000_000_000))
        
        _ = try await stopRecording()
        
        return qualityMetrics
    }
}

// MARK: - Taskå–æ¶ˆæ‰©å±•
extension AudioService {
    private func withTaskCancellation<T>(_ operation: () async throws -> T) async throws -> T {
        return try await withTaskCancellationHandler(
            operation: operation,
            onCancel: {
                Task { @MainActor in
                    self.cancelRecording()
                }
            }
        )
    }
}
//
//  AudioService.swift
//  HelloPrompt
//
//  éŸ³é¢‘å½•åˆ¶æœåŠ¡ - å®ç°AVFoundationå½•éŸ³ã€VADæ£€æµ‹ã€éŸ³é¢‘è´¨é‡æ§åˆ¶
//  Copyright Â© 2025 HelloPrompt. All rights reserved.
//

import Foundation
import AVFoundation

// MARK: - éŸ³é¢‘è´¨é‡é…ç½®
struct AudioQualityConfig {
    let sampleRate: Double = 16000.0
    let channels: Int = 1
    let bitDepth: Int = 16
    let bufferSize: Int = 1024
    let format: AudioFormatID = kAudioFormatLinearPCM
}

// MARK: - VADé…ç½®
struct VADConfig {
    let threshold: Float = 0.015         // éŸ³é‡é˜ˆå€¼ï¼ˆé™ä½ä»¥æé«˜çµæ•åº¦ï¼‰
    let minSpeechDuration: TimeInterval = 0.8    // æœ€å°è¯­éŸ³æŒç»­æ—¶é—´ï¼ˆå¢åŠ ä»¥é¿å…è¯¯è§¦å‘ï¼‰
    let maxSilenceDuration: TimeInterval = 1.5   // æœ€å¤§é™éŸ³æŒç»­æ—¶é—´ï¼ˆå¢åŠ ä»¥ç»™ç”¨æˆ·æ€è€ƒæ—¶é—´ï¼‰
    let windowSize: Int = 512            // åˆ†æçª—å£å¤§å°
    let maxRecordingDuration: TimeInterval = 500.0  // æœ€å¤§å½•éŸ³æ—¶é•¿(ç§’)
}

// MARK: - éŸ³é¢‘å½•åˆ¶çŠ¶æ€
enum AudioRecordingState: Equatable {
    case idle           // ç©ºé—²
    case preparing      // å‡†å¤‡ä¸­
    case recording      // å½•éŸ³ä¸­
    case processing     // å¤„ç†ä¸­
    case completed      // å®Œæˆ
    case error(Error)   // é”™è¯¯
    
    static func == (lhs: AudioRecordingState, rhs: AudioRecordingState) -> Bool {
        switch (lhs, rhs) {
        case (.idle, .idle),
             (.preparing, .preparing),
             (.recording, .recording),
             (.processing, .processing),
             (.completed, .completed):
            return true
        case (.error, .error):
            return true // ç®€åŒ–å¤„ç†ï¼Œåªæ¯”è¾ƒçŠ¶æ€ç±»å‹
        default:
            return false
        }
    }
}

// MARK: - éŸ³é¢‘æ•°æ®ç»“æ„
struct AudioData {
    let data: Data
    let duration: TimeInterval
    let sampleRate: Double
    let channels: Int
    let rmsLevel: Float
    let peakLevel: Float
    let hasVoiceActivity: Bool
}

// MARK: - éŸ³é¢‘æœåŠ¡åè®®
@MainActor
protocol AudioServiceDelegate: AnyObject {
    func audioService(_ service: AudioService, didChangeState state: AudioRecordingState)
    func audioService(_ service: AudioService, didDetectVoiceActivity active: Bool)
    func audioService(_ service: AudioService, didUpdateLevel rms: Float, peak: Float)
    func audioService(_ service: AudioService, didCompleteRecording audioData: AudioData)
    func audioService(_ service: AudioService, didFailWithError error: Error)
}

// MARK: - éŸ³é¢‘æœåŠ¡ä¸»ç±»
@MainActor
class AudioService: NSObject {
    
    // MARK: - Properties
    weak var delegate: AudioServiceDelegate?
    
    private var audioEngine: AVAudioEngine
    private var inputNode: AVAudioInputNode
    private var audioFile: AVAudioFile?
    private var audioBuffer: AVAudioPCMBuffer?
    
    private let qualityConfig: AudioQualityConfig
    private let vadConfig: VADConfig
    
    private var currentState: AudioRecordingState = .idle {
        didSet {
            LogManager.shared.audioLog("çŠ¶æ€å˜æ›´", details: [
                "from": "\(oldValue)",
                "to": "\(currentState)"
            ])
            delegate?.audioService(self, didChangeState: currentState)
        }
    }
    
    private var recordingStartTime: Date?
    private var audioDataBuffer = Data()
    private var rmsLevels: [Float] = []
    private var peakLevels: [Float] = []
    
    // VAD ç›¸å…³
    private var voiceActivityDetected = false
    private var lastVoiceActivityTime: Date?
    private var speechStartTime: Date?
    
    // å½•éŸ³æ—¶é•¿ç›‘æ§
    private var maxDurationTimer: Timer?
    
    // MARK: - Initialization
    override init() {
        self.audioEngine = AVAudioEngine()
        self.inputNode = audioEngine.inputNode
        self.qualityConfig = AudioQualityConfig()
        self.vadConfig = VADConfig()
        
        super.init()
        
        LogManager.shared.audioLog("AudioServiceåŸºç¡€åˆå§‹åŒ–", details: [
            "sampleRate": qualityConfig.sampleRate,
            "channels": qualityConfig.channels,
            "bufferSize": qualityConfig.bufferSize
        ])
        
        setupAudioSession()
        
        // å»¶è¿Ÿè®¾ç½®éŸ³é¢‘å¼•æ“ï¼Œé¿å…é˜»å¡åˆå§‹åŒ–
        Task { @MainActor in
            await setupAudioEngineAsync()
        }
    }
    
    deinit {
        cleanupSync()
    }
    
    // MARK: - Public Methods
    
    /// å¼€å§‹å½•éŸ³
    func startRecording() {
        LogManager.shared.audioLog("å¼€å§‹å½•éŸ³è¯·æ±‚")
        
        guard currentState == .idle else {
            LogManager.shared.warning(.audio, "å½•éŸ³çŠ¶æ€æ— æ•ˆ", metadata: ["currentState": "\(currentState)"])
            return
        }
        
        currentState = .preparing
        
        Task {
            do {
                try await prepareRecording()
                try await beginRecording()
            } catch {
                LogManager.shared.trackError(error, context: "å¼€å§‹å½•éŸ³", recoveryAction: "æ£€æŸ¥éº¦å…‹é£æƒé™å’ŒéŸ³é¢‘è®¾å¤‡")
                currentState = .error(error)
                delegate?.audioService(self, didFailWithError: error)
            }
        }
    }
    
    /// åœæ­¢å½•éŸ³
    func stopRecording() {
        LogManager.shared.audioLog("åœæ­¢å½•éŸ³è¯·æ±‚")
        
        guard currentState == .recording else {
            LogManager.shared.warning(.audio, "å½“å‰æœªåœ¨å½•éŸ³", metadata: ["currentState": "\(currentState)"])
            return
        }
        
        currentState = .processing
        
        Task {
            await finishRecording()
        }
    }
    
    /// å–æ¶ˆå½•éŸ³
    func cancelRecording() {
        LogManager.shared.audioLog("å–æ¶ˆå½•éŸ³")
        stopMaxDurationTimer()
        cleanup()
        currentState = .idle
    }
    
    // MARK: - Private Methods
    
    /// è®¾ç½®éŸ³é¢‘ä¼šè¯
    private func setupAudioSession() {
        // åœ¨macOSä¸Šï¼ŒéŸ³é¢‘ä¼šè¯é…ç½®æ˜¯è‡ªåŠ¨å¤„ç†çš„ï¼Œä¸éœ€è¦æ‰‹åŠ¨è®¾ç½®
        // è¿™é‡Œæˆ‘ä»¬åªè®°å½•ä¸€ä¸‹åˆå§‹åŒ–ä¿¡æ¯
        LogManager.shared.audioLog("éŸ³é¢‘ä¼šè¯é…ç½®æˆåŠŸï¼ˆmacOSè‡ªåŠ¨å¤„ç†ï¼‰", details: [
            "platform": "macOS",
            "note": "éŸ³é¢‘ä¼šè¯ç”±ç³»ç»Ÿè‡ªåŠ¨ç®¡ç†"
        ])
    }
    
    /// å¼‚æ­¥è®¾ç½®éŸ³é¢‘å¼•æ“
    private func setupAudioEngineAsync() async {
        LogManager.shared.audioLog("ğŸµ éŸ³é¢‘å¤„ç†: å¼€å§‹å¼‚æ­¥è®¾ç½®éŸ³é¢‘å¼•æ“")
        
        await Task.yield() // è®©å‡ºæ§åˆ¶æƒ
        
        do {
            try setupAudioEngine()
            LogManager.shared.audioLog("âœ… éŸ³é¢‘å¤„ç†: å¼‚æ­¥éŸ³é¢‘å¼•æ“è®¾ç½®å®Œæˆ")
        } catch {
            LogManager.shared.error(.audio, "éŸ³é¢‘å¼•æ“å¼‚æ­¥è®¾ç½®å¤±è´¥", metadata: [
                "error": error.localizedDescription
            ])
        }
    }
    
    /// è®¾ç½®éŸ³é¢‘å¼•æ“
    private func setupAudioEngine() throws {
        let inputFormat = inputNode.outputFormat(forBus: 0)
        let recordingFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32,
                                          sampleRate: qualityConfig.sampleRate,
                                          channels: AVAudioChannelCount(qualityConfig.channels),
                                          interleaved: false)!
        
        LogManager.shared.audioLog("éŸ³é¢‘æ ¼å¼é…ç½®", details: [
            "inputSampleRate": inputFormat.sampleRate,
            "inputChannels": inputFormat.channelCount,
            "recordingSampleRate": recordingFormat.sampleRate,
            "recordingChannels": recordingFormat.channelCount
        ])
        
        // ç¡®ä¿åœ¨å®‰è£…æ–°tapä¹‹å‰ç§»é™¤ä»»ä½•ç°æœ‰çš„tap
        do {
            inputNode.removeTap(onBus: 0)
            LogManager.shared.audioLog("æ¸…ç†ç°æœ‰çš„éŸ³é¢‘tap")
        } catch {
            // å¦‚æœæ²¡æœ‰ç°æœ‰tapï¼Œè¿™æ˜¯æ­£å¸¸çš„
            LogManager.shared.debug(.audio, "æ²¡æœ‰ç°æœ‰tapéœ€è¦æ¸…ç†")
        }
        
        // ä½¿ç”¨ç¡¬ä»¶è¾“å…¥æ ¼å¼å®‰è£…tapï¼Œé¿å…æ ¼å¼ä¸åŒ¹é…é”™è¯¯
        do {
            inputNode.installTap(onBus: 0, bufferSize: AVAudioFrameCount(qualityConfig.bufferSize), format: inputFormat) { [weak self] buffer, time in
                Task { @MainActor in
                    await self?.processAudioBuffer(buffer, at: time, targetFormat: recordingFormat)
                }
            }
            
            LogManager.shared.audioLog("éŸ³é¢‘å¤„ç†èŠ‚ç‚¹å®‰è£…æˆåŠŸ", details: [
                "tapFormat": "ä½¿ç”¨ç¡¬ä»¶è¾“å…¥æ ¼å¼ (\(inputFormat.sampleRate)Hz, \(inputFormat.channelCount)ch)",
                "targetFormat": "è½¬æ¢åˆ°ç›®æ ‡æ ¼å¼ (\(recordingFormat.sampleRate)Hz, \(recordingFormat.channelCount)ch)"
            ])
        } catch {
            LogManager.shared.error(.audio, "å®‰è£…éŸ³é¢‘å¤„ç†èŠ‚ç‚¹å¤±è´¥", metadata: [
                "error": error.localizedDescription,
                "inputFormat": "\(inputFormat.sampleRate)Hz, \(inputFormat.channelCount)ch",
                "bufferSize": qualityConfig.bufferSize
            ])
            throw AudioServiceError.audioEngineFailure
        }
    }
    
    /// å‡†å¤‡å½•éŸ³
    private func prepareRecording() async throws {
        LogManager.shared.audioLog("å‡†å¤‡å½•éŸ³ç¯å¢ƒ")
        
        // è¯·æ±‚éº¦å…‹é£æƒé™ï¼ˆmacOSç‰ˆæœ¬ï¼‰
        let permissionGranted = await withCheckedContinuation { continuation in
            AVCaptureDevice.requestAccess(for: .audio) { granted in
                continuation.resume(returning: granted)
            }
        }
        
        guard permissionGranted else {
            throw AudioServiceError.permissionDenied
        }
        
        // é‡ç½®å½•éŸ³æ•°æ®
        audioDataBuffer.removeAll()
        rmsLevels.removeAll()
        peakLevels.removeAll()
        voiceActivityDetected = false
        lastVoiceActivityTime = nil
        speechStartTime = nil
        
        LogManager.shared.audioLog("å½•éŸ³ç¯å¢ƒå‡†å¤‡å®Œæˆ", details: [
            "permission": "granted",
            "bufferCleared": true,
            "vadReset": true
        ])
    }
    
    /// å¼€å§‹å½•éŸ³
    private func beginRecording() async throws {
        recordingStartTime = Date()
        
        // æ£€æŸ¥éŸ³é¢‘å¼•æ“çŠ¶æ€ï¼Œç¡®ä¿å¹²å‡€çš„å¯åŠ¨ç¯å¢ƒ
        if audioEngine.isRunning {
            LogManager.shared.warning(.audio, "éŸ³é¢‘å¼•æ“å·²åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢å†é‡æ–°æ‰§è¡Œè®¾ç½®")
            audioEngine.stop()
            audioEngine.reset()
            
            // é‡æ–°è®¾ç½®éŸ³é¢‘å¼•æ“ä»¥ç¡®ä¿tapæ­£ç¡®å®‰è£…
            try setupAudioEngine()
        }
        
        do {
            try audioEngine.start()
            
            // éªŒè¯éŸ³é¢‘å¼•æ“æ˜¯å¦æˆåŠŸå¯åŠ¨
            guard audioEngine.isRunning else {
                throw AudioServiceError.audioEngineFailure
            }
            
            // è·å–å½“å‰è¾“å…¥æ ¼å¼ä¿¡æ¯ç”¨äºæ—¥å¿—
            let inputFormat = inputNode.outputFormat(forBus: 0)
            
            LogManager.shared.audioLog("éŸ³é¢‘å¼•æ“å¯åŠ¨æˆåŠŸ", details: [
                "engineRunning": audioEngine.isRunning,
                "inputFormat": "\(inputFormat.sampleRate)Hz, \(inputFormat.channelCount)ch",
                "targetFormat": "\(qualityConfig.sampleRate)Hz, \(qualityConfig.channels)ch"
            ])
            
            currentState = .recording
        } catch {
            LogManager.shared.error(.audio, "éŸ³é¢‘å¼•æ“å¯åŠ¨å¤±è´¥", metadata: [
                "error": error.localizedDescription,
                "engineRunning": audioEngine.isRunning,
                "errorType": "\(type(of: error))"
            ])
            
            // å°è¯•é‡ç½®éŸ³é¢‘å¼•æ“å¹¶é‡æ–°è®¾ç½®
            audioEngine.reset()
            try setupAudioEngine()
            throw AudioServiceError.audioEngineFailure
        }
        
        LogManager.shared.audioLog("å½•éŸ³å¼€å§‹", details: [
            "startTime": recordingStartTime?.description ?? "unknown",
            "engineRunning": audioEngine.isRunning,
            "maxDuration": vadConfig.maxRecordingDuration
        ])
        
        // å¼€å§‹VADç›‘å¬
        startVADMonitoring()
        
        // å¯åŠ¨æœ€å¤§å½•éŸ³æ—¶é•¿å®šæ—¶å™¨
        startMaxDurationTimer()
    }
    
    /// å¤„ç†éŸ³é¢‘ç¼“å†²åŒºï¼Œæ”¯æŒæ ¼å¼è½¬æ¢
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer, at time: AVAudioTime, targetFormat: AVAudioFormat? = nil) async {
        // æ£€æŸ¥å½“å‰çŠ¶æ€ï¼Œåªåœ¨å½•éŸ³çŠ¶æ€ä¸‹å¤„ç†ç¼“å†²åŒº
        guard currentState == .recording else {
            LogManager.shared.debug(.audio, "éŸ³é¢‘ç¼“å†²åŒºå¤„ç†è¢«è·³è¿‡", metadata: ["currentState": "\(currentState)"])
            return
        }
        
        guard let channelData = buffer.floatChannelData else { 
            LogManager.shared.warning(.audio, "éŸ³é¢‘ç¼“å†²åŒºç¼ºå°‘é€šé“æ•°æ®")
            return 
        }
        
        let frameCount = Int(buffer.frameLength)
        var samples: [Float]
        
        // è·å–è¾“å…¥éŸ³é¢‘æ ¼å¼ä¿¡æ¯
        let inputSampleRate = buffer.format.sampleRate
        let inputChannelCount = Int(buffer.format.channelCount)
        
        // æ ¼å¼è½¬æ¢å¤„ç†
        if let targetFormat = targetFormat,
           inputSampleRate != targetFormat.sampleRate || 
           inputChannelCount != Int(targetFormat.channelCount) {
            
            LogManager.shared.debug(.audio, "æ‰§è¡ŒéŸ³é¢‘æ ¼å¼è½¬æ¢", metadata: [
                "è¾“å…¥æ ¼å¼": "\(inputSampleRate)Hz, \(inputChannelCount)ch",
                "ç›®æ ‡æ ¼å¼": "\(targetFormat.sampleRate)Hz, \(targetFormat.channelCount)ch",
                "å¸§æ•°": frameCount
            ])
            
            // å¤„ç†å¤šå£°é“åˆ°å•å£°é“çš„è½¬æ¢
            if inputChannelCount > 1 && Int(targetFormat.channelCount) == 1 {
                // æ··åˆæ‰€æœ‰å£°é“åˆ°å•å£°é“
                samples = []
                samples.reserveCapacity(frameCount)
                for i in 0..<frameCount {
                    var mixedSample: Float = 0
                    for channel in 0..<inputChannelCount {
                        mixedSample += channelData[channel][i]
                    }
                    samples.append(mixedSample / Float(inputChannelCount))
                }
                LogManager.shared.debug(.audio, "å®Œæˆå¤šå£°é“åˆ°å•å£°é“è½¬æ¢", metadata: [
                    "åŸå§‹å£°é“æ•°": inputChannelCount,
                    "è½¬æ¢åå£°é“æ•°": 1,
                    "æ ·æœ¬æ•°": samples.count
                ])
            } else {
                // ç›´æ¥ä½¿ç”¨ç¬¬ä¸€ä¸ªå£°é“
                samples = Array(UnsafeBufferPointer(start: channelData[0], count: frameCount))
            }
            
            // é‡‡æ ·ç‡è½¬æ¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if inputSampleRate != targetFormat.sampleRate {
                let ratio = inputSampleRate / targetFormat.sampleRate
                let targetFrameCount = Int(Double(frameCount) / ratio)
                var resampledSamples: [Float] = []
                resampledSamples.reserveCapacity(targetFrameCount)
                
                for i in 0..<targetFrameCount {
                    let sourceIndex = Int(Double(i) * ratio)
                    if sourceIndex < samples.count {
                        resampledSamples.append(samples[sourceIndex])
                    }
                }
                samples = resampledSamples
                
                LogManager.shared.debug(.audio, "å®Œæˆé‡‡æ ·ç‡è½¬æ¢", metadata: [
                    "åŸå§‹é‡‡æ ·ç‡": inputSampleRate,
                    "ç›®æ ‡é‡‡æ ·ç‡": targetFormat.sampleRate,
                    "åŸå§‹å¸§æ•°": frameCount,
                    "è½¬æ¢åå¸§æ•°": samples.count
                ])
            }
        } else {
            // æ— éœ€æ ¼å¼è½¬æ¢ï¼Œç›´æ¥ä½¿ç”¨ç¬¬ä¸€ä¸ªå£°é“
            samples = Array(UnsafeBufferPointer(start: channelData[0], count: frameCount))
        }
        
        // è®¡ç®—éŸ³é¢‘çº§åˆ«
        let rms = calculateRMS(samples: samples)
        let peak = calculatePeak(samples: samples)
        
        rmsLevels.append(rms)
        peakLevels.append(peak)
        
        // VADæ£€æµ‹
        let voiceActive = detectVoiceActivity(rms: rms, peak: peak)
        
        // æ£€æŸ¥è‡ªåŠ¨åœæ­¢æ¡ä»¶
        await checkAutoStopCondition(voiceActive: voiceActive)
        
        // é€šçŸ¥ä»£ç†éŸ³é¢‘çº§åˆ«æ›´æ–°
        delegate?.audioService(self, didUpdateLevel: rms, peak: peak)
        
        // å¦‚æœæ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨å˜åŒ–ï¼Œé€šçŸ¥ä»£ç†
        if voiceActive != voiceActivityDetected {
            voiceActivityDetected = voiceActive
            delegate?.audioService(self, didDetectVoiceActivity: voiceActive)
            
            LogManager.shared.audioLog("VADçŠ¶æ€å˜æ›´", details: [
                "voiceActive": voiceActive,
                "rms": rms,
                "peak": peak,
                "threshold": vadConfig.threshold
            ])
        }
        
        // å°†å¤„ç†åçš„éŸ³é¢‘æ•°æ®æ·»åŠ åˆ°ç¼“å†²åŒº
        let data = Data(bytes: samples, count: samples.count * MemoryLayout<Float>.size)
        audioDataBuffer.append(data)
        
        // æ€§èƒ½ç›‘æ§
        if rmsLevels.count % 100 == 0 {
            let avgRMS = rmsLevels.suffix(100).reduce(0, +) / 100
            LogManager.shared.performanceLog("éŸ³é¢‘å¤„ç†", duration: 0.001, details: [
                "bufferSize": frameCount,
                "avgRMS": avgRMS,
                "dataSize": audioDataBuffer.count
            ])
        }
    }
    
    /// å®Œæˆå½•éŸ³
    private func finishRecording() async {
        LogManager.shared.audioLog("å¼€å§‹å®Œæˆå½•éŸ³å¤„ç†")
        
        // å®‰å…¨åœæ­¢éŸ³é¢‘å¼•æ“
        if audioEngine.isRunning {
            audioEngine.stop()
            LogManager.shared.audioLog("éŸ³é¢‘å¼•æ“å·²åœæ­¢")
        } else {
            LogManager.shared.warning(.audio, "éŸ³é¢‘å¼•æ“æœªåœ¨è¿è¡ŒçŠ¶æ€")
        }
        
        // æ¸…ç†å®šæ—¶å™¨
        stopMaxDurationTimer()
        
        let endTime = Date()
        let duration = endTime.timeIntervalSince(recordingStartTime ?? endTime)
        
        // è®¡ç®—æœ€ç»ˆç»Ÿè®¡æ•°æ®
        let avgRMS = rmsLevels.isEmpty ? 0 : rmsLevels.reduce(0, +) / Float(rmsLevels.count)
        let maxPeak = peakLevels.max() ?? 0
        let hasVoice = voiceActivityDetected || speechStartTime != nil
        
        let audioData = AudioData(
            data: audioDataBuffer,
            duration: duration,
            sampleRate: qualityConfig.sampleRate,
            channels: qualityConfig.channels,
            rmsLevel: avgRMS,
            peakLevel: maxPeak,
            hasVoiceActivity: hasVoice
        )
        
        LogManager.shared.audioLog("å½•éŸ³å®Œæˆ", details: [
            "duration": String(format: "%.2fs", duration),
            "dataSize": "\(audioDataBuffer.count) bytes",
            "avgRMS": avgRMS,
            "maxPeak": maxPeak,
            "hasVoiceActivity": hasVoice,
            "sampleCount": rmsLevels.count
        ])
        
        currentState = .completed
        delegate?.audioService(self, didCompleteRecording: audioData)
        
        // é‡ç½®çŠ¶æ€
        currentState = .idle
    }
    
    /// å¼€å§‹VADç›‘å¬
    private func startVADMonitoring() {
        LogManager.shared.audioLog("å¼€å§‹VADç›‘å¬", details: [
            "threshold": vadConfig.threshold,
            "minSpeechDuration": vadConfig.minSpeechDuration,
            "maxSilenceDuration": vadConfig.maxSilenceDuration
        ])
    }
    
    /// VADæ£€æµ‹
    private func detectVoiceActivity(rms: Float, peak: Float) -> Bool {
        let isActiveNow = rms > vadConfig.threshold || peak > vadConfig.threshold * 2
        let now = Date()
        
        if isActiveNow {
            lastVoiceActivityTime = now
            if speechStartTime == nil {
                speechStartTime = now
                LogManager.shared.audioLog("æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹", details: [
                    "rms": rms,
                    "peak": peak,
                    "threshold": vadConfig.threshold
                ])
            }
        } else if let lastActivity = lastVoiceActivityTime {
            // æ£€æŸ¥é™éŸ³æŒç»­æ—¶é—´
            if now.timeIntervalSince(lastActivity) > vadConfig.maxSilenceDuration {
                speechStartTime = nil
            }
        }
        
        return isActiveNow
    }
    
    /// æ£€æŸ¥è‡ªåŠ¨åœæ­¢æ¡ä»¶
    private func checkAutoStopCondition(voiceActive: Bool) async {
        guard currentState == .recording else { return }
        
        let now = Date()
        
        // å¦‚æœæ£€æµ‹åˆ°è¶³å¤Ÿçš„è¯­éŸ³å¹¶ä¸”å½“å‰å¤„äºé™éŸ³çŠ¶æ€
        if !voiceActive,
           let speechStart = speechStartTime,
           let lastActivity = lastVoiceActivityTime {
            
            let speechDuration = lastActivity.timeIntervalSince(speechStart)
            let silenceDuration = now.timeIntervalSince(lastActivity)
            
            // æ»¡è¶³è‡ªåŠ¨åœæ­¢æ¡ä»¶ï¼š
            // 1. è¯­éŸ³æŒç»­æ—¶é—´è¶…è¿‡æœ€å°é˜ˆå€¼(0.5ç§’)
            // 2. é™éŸ³æŒç»­æ—¶é—´è¶…è¿‡VADé…ç½®(é»˜è®¤0.5ç§’)
            if speechDuration >= vadConfig.minSpeechDuration && 
               silenceDuration >= vadConfig.maxSilenceDuration {
                
                LogManager.shared.audioLog("VADè‡ªåŠ¨åœæ­¢å½•éŸ³", details: [
                    "speechDuration": speechDuration,
                    "silenceDuration": silenceDuration,
                    "minSpeechDuration": vadConfig.minSpeechDuration,
                    "maxSilenceDuration": vadConfig.maxSilenceDuration
                ])
                
                // è‡ªåŠ¨åœæ­¢å½•éŸ³
                await stopRecording()
            }
        }
        
        // æ£€æŸ¥æœ€å¤§å½•éŸ³æ—¶é•¿é™åˆ¶
        if let recordingStart = recordingStartTime {
            let recordingDuration = now.timeIntervalSince(recordingStart)
            if recordingDuration >= vadConfig.maxRecordingDuration {
                LogManager.shared.audioLog("è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿ï¼Œè‡ªåŠ¨åœæ­¢", details: [
                    "recordingDuration": recordingDuration,
                    "maxRecordingDuration": vadConfig.maxRecordingDuration
                ])
                
                await stopRecording()
            }
        }
    }
    
    /// è®¡ç®—RMSéŸ³é‡
    private func calculateRMS(samples: [Float]) -> Float {
        let sum = samples.reduce(0) { $0 + $1 * $1 }
        return sqrt(sum / Float(samples.count))
    }
    
    /// è®¡ç®—å³°å€¼éŸ³é‡
    private func calculatePeak(samples: [Float]) -> Float {
        return samples.map(abs).max() ?? 0
    }
    
    /// å¯åŠ¨æœ€å¤§å½•éŸ³æ—¶é•¿å®šæ—¶å™¨
    private func startMaxDurationTimer() {
        maxDurationTimer = Timer.scheduledTimer(withTimeInterval: vadConfig.maxRecordingDuration, repeats: false) { [weak self] _ in
            Task { @MainActor in
                await self?.handleMaxDurationReached()
            }
        }
        
        LogManager.shared.audioLog("å½•éŸ³æ—¶é•¿ç›‘æ§å®šæ—¶å™¨å¯åŠ¨", details: [
            "maxDuration": vadConfig.maxRecordingDuration,
            "timerScheduled": true
        ])
    }
    
    /// åœæ­¢æœ€å¤§å½•éŸ³æ—¶é•¿å®šæ—¶å™¨
    private func stopMaxDurationTimer() {
        maxDurationTimer?.invalidate()
        maxDurationTimer = nil
        
        LogManager.shared.audioLog("å½•éŸ³æ—¶é•¿ç›‘æ§å®šæ—¶å™¨å·²åœæ­¢")
    }
    
    /// å¤„ç†è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿
    private func handleMaxDurationReached() async {
        LogManager.shared.warning(.audio, "å½•éŸ³æ—¶é•¿è¾¾åˆ°æœ€å¤§é™åˆ¶", metadata: [
            "maxDuration": vadConfig.maxRecordingDuration,
            "action": "è‡ªåŠ¨åœæ­¢å½•éŸ³"
        ])
        
        // è‡ªåŠ¨åœæ­¢å½•éŸ³
        if currentState == .recording {
            await finishRecording()
            
            // é€šçŸ¥ä»£ç†è¾¾åˆ°æœ€å¤§æ—¶é•¿
            delegate?.audioService(self, didFailWithError: AudioServiceError.maxDurationReached)
        }
    }
    
    /// æ¸…ç†èµ„æº
    private func cleanup() {
        LogManager.shared.audioLog("å¼€å§‹æ¸…ç†éŸ³é¢‘èµ„æº")
        
        // åœæ­¢éŸ³é¢‘å¼•æ“å¹¶é‡ç½®çŠ¶æ€
        if audioEngine.isRunning {
            audioEngine.stop()
            LogManager.shared.audioLog("éŸ³é¢‘å¼•æ“å·²åœæ­¢")
        }
        
        // å®‰å…¨ç§»é™¤tap
        inputNode.removeTap(onBus: 0)
        LogManager.shared.audioLog("éŸ³é¢‘tapå·²ç§»é™¤")
        
        // é‡ç½®éŸ³é¢‘å¼•æ“ä»¥ç¡®ä¿å®Œå…¨æ¸…ç†
        audioEngine.reset()
        LogManager.shared.audioLog("éŸ³é¢‘å¼•æ“å·²é‡ç½®")
        
        // æ¸…ç†å®šæ—¶å™¨
        stopMaxDurationTimer()
        
        // æ¸…ç†éŸ³é¢‘æ•°æ®ç¼“å†²åŒº
        audioDataBuffer.removeAll(keepingCapacity: false) // é‡Šæ”¾å†…å­˜
        rmsLevels.removeAll(keepingCapacity: false)
        peakLevels.removeAll(keepingCapacity: false)
        
        // é‡ç½®VADçŠ¶æ€
        voiceActivityDetected = false
        lastVoiceActivityTime = nil
        speechStartTime = nil
        recordingStartTime = nil
        
        LogManager.shared.audioLog("éŸ³é¢‘èµ„æºæ¸…ç†å®Œæˆ", details: [
            "bufferCleared": true,
            "levelsCleared": true,
            "vadReset": true,
            "timersCleared": true
        ])
    }
    
    /// åŒæ­¥æ¸…ç†æ–¹æ³•ï¼Œç”¨äºdeinit
    nonisolated private func cleanupSync() {
        Task { @MainActor in
            if audioEngine.isRunning {
                audioEngine.stop()
            }
            inputNode.removeTap(onBus: 0)
            audioDataBuffer.removeAll()
            rmsLevels.removeAll()
            peakLevels.removeAll()
            
            LogManager.shared.audioLog("éŸ³é¢‘èµ„æºæ¸…ç†å®Œæˆï¼ˆåŒæ­¥ï¼‰")
        }
    }
}

// MARK: - éŸ³é¢‘æœåŠ¡é”™è¯¯ç±»å‹
enum AudioServiceError: LocalizedError {
    case permissionDenied
    case audioEngineFailure
    case recordingFailed
    case invalidAudioFormat
    case maxDurationReached
    
    var errorDescription: String? {
        switch self {
        case .permissionDenied:
            return "éº¦å…‹é£æƒé™è¢«æ‹’ç»"
        case .audioEngineFailure:
            return "éŸ³é¢‘å¼•æ“å¯åŠ¨å¤±è´¥"
        case .recordingFailed:
            return "å½•éŸ³è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯"
        case .invalidAudioFormat:
            return "ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼"
        case .maxDurationReached:
            return "å½•éŸ³æ—¶é•¿è¶…è¿‡æœ€å¤§é™åˆ¶(500ç§’)ï¼Œå·²è‡ªåŠ¨åœæ­¢"
        }
    }
}